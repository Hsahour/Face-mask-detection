{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ea17e7-d640-40e4-9ac9-6914e1abea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1203bbd-44a4-4855-9a9e-8671d806f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "\n",
    "# keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7aeceb-f2b2-4c35-885c-1ec91e43f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hosse\\anaconda3\\envs\\geospatial\\lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.12.2 when it was built against 1.12.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Found 992 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "312/312 [==============================] - 333s 1s/step - loss: 0.5259 - acc: 0.7371 - val_loss: 0.8524 - val_acc: 0.5725\n",
      "Epoch 2/30\n",
      "312/312 [==============================] - 331s 1s/step - loss: 0.4031 - acc: 0.8210 - val_loss: 0.6635 - val_acc: 0.6787\n",
      "Epoch 3/30\n",
      "312/312 [==============================] - 331s 1s/step - loss: 0.3490 - acc: 0.8512 - val_loss: 0.3124 - val_acc: 0.8487\n",
      "Epoch 4/30\n",
      "312/312 [==============================] - 329s 1s/step - loss: 0.3009 - acc: 0.8779 - val_loss: 0.2602 - val_acc: 0.8813\n",
      "Epoch 5/30\n",
      "312/312 [==============================] - 330s 1s/step - loss: 0.2929 - acc: 0.8811 - val_loss: 0.2195 - val_acc: 0.9262\n",
      "Epoch 6/30\n",
      "312/312 [==============================] - 345s 1s/step - loss: 0.2777 - acc: 0.8857 - val_loss: 0.2202 - val_acc: 0.8950\n",
      "Epoch 7/30\n",
      "312/312 [==============================] - 331s 1s/step - loss: 0.2736 - acc: 0.8885 - val_loss: 1.6560 - val_acc: 0.5625\n",
      "Epoch 8/30\n",
      "312/312 [==============================] - 348s 1s/step - loss: 0.2456 - acc: 0.9026 - val_loss: 0.5137 - val_acc: 0.7513\n",
      "Epoch 9/30\n",
      "312/312 [==============================] - 336s 1s/step - loss: 0.2509 - acc: 0.8969 - val_loss: 0.1964 - val_acc: 0.9212\n",
      "Epoch 10/30\n",
      "312/312 [==============================] - 339s 1s/step - loss: 0.2560 - acc: 0.8951 - val_loss: 0.5432 - val_acc: 0.7387\n",
      "Epoch 11/30\n",
      "312/312 [==============================] - 328s 1s/step - loss: 0.2362 - acc: 0.9074 - val_loss: 2.1355 - val_acc: 0.5050\n",
      "Epoch 12/30\n",
      "312/312 [==============================] - 329s 1s/step - loss: 0.2388 - acc: 0.9069 - val_loss: 0.1513 - val_acc: 0.9413\n",
      "Epoch 13/30\n",
      "312/312 [==============================] - 327s 1s/step - loss: 0.2295 - acc: 0.9088 - val_loss: 0.1364 - val_acc: 0.9513\n",
      "Epoch 14/30\n",
      "312/312 [==============================] - 330s 1s/step - loss: 0.2371 - acc: 0.9051 - val_loss: 0.2839 - val_acc: 0.8712\n",
      "Epoch 15/30\n",
      "312/312 [==============================] - 328s 1s/step - loss: 0.2327 - acc: 0.9096 - val_loss: 0.1492 - val_acc: 0.9450\n",
      "Epoch 16/30\n",
      "312/312 [==============================] - 327s 1s/step - loss: 0.2223 - acc: 0.9099 - val_loss: 0.8090 - val_acc: 0.6413\n",
      "Epoch 17/30\n",
      "312/312 [==============================] - 327s 1s/step - loss: 0.2113 - acc: 0.9206 - val_loss: 0.2355 - val_acc: 0.8900\n",
      "Epoch 18/30\n",
      "312/312 [==============================] - 329s 1s/step - loss: 0.2217 - acc: 0.9106 - val_loss: 0.1527 - val_acc: 0.9438\n",
      "31/31 [==============================] - 28s 894ms/step - loss: 0.1328 - acc: 0.9536\n",
      "Test accuracy: 0.9536290168762207\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "train_dir= r'Train'\n",
    "test_dir= r'Test'\n",
    "validation_dir= r'Validation'\n",
    "\n",
    "# Load ResNet50 pre-trained model\n",
    "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Fine-tune the last few layers\n",
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the model with additional dense layers\n",
    "model = models.Sequential([\n",
    "    conv_base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'), \n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Data augmentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,              \n",
    "    rotation_range=20,           \n",
    "    width_shift_range=0.1,       \n",
    "    height_shift_range=0.1,      \n",
    "    shear_range=0.1,             \n",
    "    zoom_range=0.1,              \n",
    "    horizontal_flip=True,        \n",
    "    fill_mode='nearest'          \n",
    ")\n",
    "\n",
    "# Rescaling for validation and test sets\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = validation_generator.samples // validation_generator.batch_size\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_cb = ModelCheckpoint(\"best_model_resnet50.h5\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=30,  # Increased epochs for better training\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db216cc-54e2-4fc5-810b-0f59b6878936",
   "metadata": {},
   "source": [
    "Real Time Mask Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52865452-9fc6-45ad-88c6-0b4fbc985e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = load_model(\"final_resnet50_model.h5\")\n",
    "\n",
    "# Define Haar Cascade for face detection\n",
    "cascade_path = r'C:\\Users\\hosse\\Downloads\\Final_Assignment_Face Mask Dataset\\haarcascade_frontalface_default.xml'\n",
    "face_clsfr = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "# Labels and colors for mask detection\n",
    "labels_dict = {0: 'with_mask', 1: 'without_mask'}\n",
    "color_dict = {0: (0, 255, 0), 1: (0, 0, 255)}  \n",
    "\n",
    "# Initialize webcam\n",
    "webcam = cv2.VideoCapture(0) \n",
    "\n",
    "# Ensure webcam opened successfully\n",
    "if not webcam.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "size = 4  # Resize scale factor for speeding up detection\n",
    "\n",
    "while True:\n",
    "    rval, im = webcam.read() \n",
    "    if not rval:\n",
    "        print(\"Error: Could not read from webcam.\")\n",
    "        break\n",
    "\n",
    "    im = cv2.flip(im, 1)  # Flip horizontally (like a mirror)\n",
    "\n",
    "    # Resize image to speed up face detection\n",
    "    mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
    "\n",
    "    # Detect faces in the resized image\n",
    "    faces = face_clsfr.detectMultiScale(mini, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Loop through detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        (x, y, w, h) = [v * size for v in (x, y, w, h)]  # Scale back to original size\n",
    "        face_img = im[y:y+h, x:x+w]  # Crop the face from the image\n",
    "\n",
    "        # Preprocess the face image\n",
    "        resized = cv2.resize(face_img, (224, 224))  # Resize to (224, 224) as required by the model\n",
    "        normalized = resized / 255.0  # Normalize the pixel values to [0, 1]\n",
    "        reshaped = np.reshape(normalized, (1, 224, 224, 3))  # Reshape to match model input (1, 224, 224, 3)\n",
    "\n",
    "        cv2.imshow(\"Cropped Face\", face_img)\n",
    "        cv2.waitKey(1)  \n",
    "        \n",
    "        # Predict mask status\n",
    "        result = model.predict(reshaped)\n",
    "        probability = result[0][0]  # Get the sigmoid output probability\n",
    "\n",
    "        # Set a threshold for binary classification (default is 0.5)\n",
    "        if probability > 0.5:\n",
    "            label = 1  # \"without_mask\"\n",
    "        else:\n",
    "            label = 0  # \"with_mask\"\n",
    "\n",
    "        # Draw a rectangle around the face and display the label\n",
    "        cv2.rectangle(im, (x, y), (x+w, y+h), color_dict[label], 2)\n",
    "        cv2.rectangle(im, (x, y-40), (x+w, y), color_dict[label], -1)  # Draw filled rectangle for label background\n",
    "        cv2.putText(im, labels_dict[label], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the live image with detections\n",
    "    cv2.imshow('LIVE', im)\n",
    "\n",
    "    # Exit the loop on 'Esc' key\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:  # 27 is the ASCII code for the 'Esc' key\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359aa4bc-88f3-4d2f-af93-ebe624fe97bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
